Governments:
  MarkdownContext: |
    ## Governments & Security Establishments
    - **Influence**: Can legislate compute caps, enforce reporting, establish oversight agencies, and negotiate international treaties. Security establishments must shift from AGI “Manhattan projects” to Tool AI “Apollo projects.”
    - **Resources/Capabilities**: Lawmaking power, export controls, intelligence and defense budgets, diplomatic channels.
    - **Motivations**:
      - Publicly: economic growth, technological leadership, scientific progress.
      - Privately: fear of rivals gaining a decisive strategic advantage; belief that AGI could revolutionize military affairs (comparable to nuclear weapons).
    - **Interactions**: Strongly influenced by corporate lobbying; in rivalry with other governments (e.g., US–China), affecting chipmakers and regulators.

Corporations:
  MarkdownContext: |
    ## Corporations (Major Technology Companies)
    - **Influence**: Directly control AI development trajectory; could stop the AGI race and redirect toward Tool AI. Possess lobbying power to resist or shape regulation.
    - **Resources/Capabilities**: Massive compute, datasets, top AI researchers, financial power, ability to frame narratives of AGI inevitability.
    - **Motivations**:
      - Enormous financial gains: potential to capture trillions by replacing human labor.
      - Drive to dominate new digital markets across all sectors simultaneously.
      - Executive visions of technological transformation and prestige.
    - **Interactions**: Depend on hardware manufacturers for chips; heavily influence governments and regulators.

HardwareManufacturers:
  MarkdownContext: |
    ## Hardware Manufacturers & Chip Supply Chain
    - **Influence**: Can embed governance features into chips, enforce compute metering, and serve as chokepoints for international verification.
    - **Resources/Capabilities**: Concentrated global supply chain (TSMC, ASML, NVIDIA, AMD), technical feasibility to implement cryptographic and security controls.
    - **Motivations**:
      - Profit from soaring chip demand, driven by AI race.
      - Competitive advantage in controlling scarce high-end chip supply.
    - **Interactions**: Depend on government mandates for governance; affected by geopolitical rivalries between governments.

Regulators:
  MarkdownContext: |
    ## Regulators & International Institutions
    - **Influence**: Can classify AGI as unacceptable risk, enforce tiered licensing, and potentially create international bodies like an AI IAEA.
    - **Resources/Capabilities**: Authority to set laws, technical standards, and enforcement regimes; ability to mandate liability.
    - **Motivations**:
      - Protect public safety and prevent systemic risks.
      - Balance innovation with oversight.
      - In practice, often pressured to prioritize economic competitiveness and industry lobbying.
    - **Interactions**: Vulnerable to corporate capture; depend on governments for legitimacy and on international cooperation for enforcement.

CivilSociety:
  MarkdownContext: |
    ## Civil Society & the Public
    - **Influence**: Can mobilize public opinion, pressure policymakers, resist AGI inevitability narratives, and demand redistributive mechanisms like data dignity.
    - **Resources/Capabilities**: NGOs, advocacy groups, democratic leverage, public polling already showing opposition to AGI.
    - **Motivations**:
      - Desire for safety, slower AI development, and protection of jobs.
      - Fear of power concentration in corporations or governments.
      - Aspirations for equitable distribution of AI benefits.
    - **Interactions**: Influence governments and regulators through democratic processes; need to build coalitions with scientists and media.

ScientificCommunity:
  MarkdownContext: |
    ## Scientific & AI Research Community
    - **Influence**: Provide technical frameworks for Tool AI and safety verification, educate the public and policymakers, reframe narratives around AI safety.
    - **Resources/Capabilities**: Technical expertise, credibility, ability to innovate safer architectures and red-team unsafe systems.
    - **Motivations**:
      - Curiosity and scientific drive to understand intelligence.
      - Desire to use AI for positive ends (medicine, science, sustainability).
      - Concern over existential risks and responsibility to warn society.
    - **Interactions**: Many researchers work in corporations, creating capture risks; align with NGOs and civil society to advocate for restraint.
